import streamlit as st
import pickle
import numpy as np
from PIL import Image
import pandas as pd

try:
    from ensemble_models import (
        RandomForest,
        VotingClassifier,
        XGBoostCustom,
        AdaBoostMulticlass  
    )
    CUSTOM_MODELS_AVAILABLE = True
except ImportError:
    CUSTOM_MODELS_AVAILABLE = False
    st.warning("Kh√¥ng t√¨m th·∫•y ensemble_models.py. Vui l√≤ng upload file n√†y!")
# C·∫•u h√¨nh trang
st.set_page_config(
    page_title="Ph√¢n lo·∫°i Hoa Iris",
    page_icon="üå∏",
    layout="wide"
)

# Ti√™u ƒë·ªÅ
st.title("üå∏ ·ª®ng d·ª•ng Ph√¢n lo·∫°i Hoa Iris")
st.markdown("### S·ª≠ d·ª•ng Ensemble Learning")
st.markdown("---")

# Sidebar ƒë·ªÉ ch·ªçn model
st.sidebar.header("‚öôÔ∏è C·∫•u h√¨nh")
model_choice = st.sidebar.selectbox(
    "Ch·ªçn Model:",
    [
        "Random Forest (Bagging)", 
        "Voting Classifier", 
        "XGBoost Custom (Boosting)",
        "AdaBoost (Boosting)"  
    ]
)

# Load model
@st.cache_resource
def load_model(model_name):
    try:
        if model_name == "Random Forest (Bagging)":
            with open('model_rf_custom.pkl', 'rb') as f:
                model = pickle.load(f)
        elif model_name == "Voting Classifier":
            with open('model_voting_custom.pkl', 'rb') as f:
                model = pickle.load(f)
        elif model_name == "XGBoost Custom (Boosting)":
            with open('model_xgboost_custom.pkl', 'rb') as f:
                model = pickle.load(f)
        else:  # AdaBoost (Boosting)
            with open('model_adaboost_custom.pkl', 'rb') as f:
                model = pickle.load(f)
        return model
    except FileNotFoundError:
        st.error(f"Kh√¥ng t√¨m th·∫•y file model! Vui l√≤ng ch·∫°y train_models.py tr∆∞·ªõc")
        return None
    except Exception as e:
        st.error(f"L·ªói khi load model: {str(e)}")
        return None
iris_names = {
    0: "Iris Setosa",
    1: "Iris Versicolor",
    2: "Iris Virginica"
}
iris_descriptions = {
    0: "**Iris Setosa**: Lo√†i hoa nh·ªè nh·∫•t, c√°nh hoa m√†u t√≠m nh·∫°t ƒë·∫øn xanh d∆∞∆°ng, d·ªÖ ph√¢n bi·ªát nh·∫•t.",
    1: "**Iris Versicolor**: Lo√†i hoa c·ª° trung b√¨nh, c√°nh hoa m√†u t√≠m, c√≥ v√¢n m√†u tr·∫Øng v√† v√†ng.",
    2: "**Iris Virginica**: Lo√†i hoa l·ªõn nh·∫•t, c√°nh hoa m√†u t√≠m ƒë·∫≠m ƒë·∫øn xanh nh·∫°t, th∆∞·ªùng cao nh·∫•t."
}

# Load h√¨nh ·∫£nh
@st.cache_data
def load_images():
    images = {}
    try:
        images[0] = Image.open('iris_setosa.jpg')
        images[1] = Image.open('iris_versicolor.jpg')
        images[2] = Image.open('iris_virginica.jpg')
    except:
        st.warning("Kh√¥ng t√¨m th·∫•y m·ªôt s·ªë h√¨nh ·∫£nh. Vui l√≤ng upload h√¨nh ·∫£nh hoa Iris.")
    return images

# Giao di·ªán nh·∫≠p li·ªáu
st.header("üìä Nh·∫≠p th√¥ng s·ªë hoa Iris")
col1, col2 = st.columns(2)
with col1:
    sepal_length = st.number_input(
        "Chi·ªÅu d√†i ƒë√†i hoa (cm)",
        min_value=0.0,
        max_value=10.0,
        value=5.1,
        step=0.1,
        help="Th√¥ng th∆∞·ªùng t·ª´ 4.3 ƒë·∫øn 7.9 cm"
    )
    sepal_width = st.number_input(
        "Chi·ªÅu r·ªông ƒë√†i hoa (cm)",
        min_value=0.0,
        max_value=10.0,
        value=3.5,
        step=0.1,
        help="Th√¥ng th∆∞·ªùng t·ª´ 2.0 ƒë·∫øn 4.4 cm"
    )
with col2:
    petal_length = st.number_input(
        "Chi·ªÅu d√†i c√°nh hoa (cm)",
        min_value=0.0,
        max_value=10.0,
        value=1.4,
        step=0.1,
        help="Th√¥ng th∆∞·ªùng t·ª´ 1.0 ƒë·∫øn 6.9 cm"
    )
    petal_width = st.number_input(
        "Chi·ªÅu r·ªông c√°nh hoa (cm)",
        min_value=0.0,
        max_value=10.0,
        value=0.2,
        step=0.1,
        help="Th√¥ng th∆∞·ªùng t·ª´ 0.1 ƒë·∫øn 2.5 cm"
    )

# N√∫t d·ª± ƒëo√°n
if st.button("üîç D·ª± ƒëo√°n lo√†i hoa", type="primary"):
    if not CUSTOM_MODELS_AVAILABLE:
        st.error("C·∫ßn file ensemble_models.py ƒë·ªÉ ch·∫°y!")
        st.stop()
    model = load_model(model_choice)

    if model is not None:
        input_data = np.array([[sepal_length, sepal_width, petal_length, petal_width]])
        try:
            prediction = model.predict(input_data)[0]
            prediction = int(prediction)
            if prediction < 0:
                prediction = 0
            elif prediction > 2:
                prediction = 2
            st.markdown("---")
            st.success("‚úÖ D·ª± ƒëo√°n ho√†n t·∫•t!")
            col1, col2 = st.columns([1, 1])
            with col1:
                st.subheader("üéØ K·∫øt qu·∫£ d·ª± ƒëo√°n")
                st.markdown(f"### {iris_names[prediction]}")
                st.info(iris_descriptions[prediction])
                st.markdown("#### üìù Th√¥ng s·ªë ƒë√£ nh·∫≠p:")
                data_df = pd.DataFrame({
                    'Th√¥ng s·ªë': ['D√†i ƒë√†i', 'R·ªông ƒë√†i', 'D√†i c√°nh', 'R·ªông c√°nh'],
                    'Gi√° tr·ªã (cm)': [sepal_length, sepal_width, petal_length, petal_width]
                })
                st.table(data_df)
                if hasattr(model, 'predict_proba'):
                    try:
                        probabilities = model.predict_proba(input_data)[0]
                        if len(probabilities) < 3:
                            probabilities = np.append(probabilities, [0] * (3 - len(probabilities)))
                        st.markdown("#### üìä X√°c su·∫•t d·ª± ƒëo√°n:")
                        prob_df = pd.DataFrame({
                            'Lo√†i hoa': [iris_names[i] for i in range(3)],
                            'X√°c su·∫•t': [f"{prob*100:.2f}%" for prob in probabilities[:3]]
                        })
                        st.table(prob_df)
                        st.bar_chart(
                            pd.DataFrame(
                                probabilities[:3],
                                index=[iris_names[i] for i in range(3)],
                                columns=['X√°c su·∫•t']
                            )
                        )
                    except:
                        pass
            with col2:
                st.subheader("üå∏ H√¨nh ·∫£nh lo√†i hoa")
                images = load_images()
                if prediction in images:
                    st.image(images[prediction], use_container_width=True)
                else:
                    st.warning("Ch∆∞a c√≥ h√¨nh ·∫£nh cho lo√†i hoa n√†y")
        except Exception as e:
            st.error(f"L·ªói khi d·ª± ƒëo√°n: {str(e)}")
            st.info("Vui l√≤ng ki·ªÉm tra l·∫°i model v√† th·ª≠ l·∫°i.")

# Th√¥ng tin v·ªÅ dataset
with st.expander("‚ÑπÔ∏è Th√¥ng tin v·ªÅ Dataset Iris"):
    st.markdown("""
    **Dataset Iris** l√† m·ªôt trong nh·ªØng dataset kinh ƒëi·ªÉn nh·∫•t trong Machine Learning, ƒë∆∞·ª£c gi·ªõi thi·ªáu b·ªüi Ronald Fisher nƒÉm 1936.

    **ƒê·∫∑c ƒëi·ªÉm:**
    - 150 m·∫´u hoa Iris
    - 3 lo√†i: Setosa, Versicolor, Virginica (m·ªói lo√†i 50 m·∫´u)
    - 4 ƒë·∫∑c tr∆∞ng: Chi·ªÅu d√†i/r·ªông ƒë√†i hoa v√† c√°nh hoa

    **Ph·∫°m vi gi√° tr·ªã th√¥ng th∆∞·ªùng:**
    - Chi·ªÅu d√†i ƒë√†i: 4.3 - 7.9 cm
    - Chi·ªÅu r·ªông ƒë√†i: 2.0 - 4.4 cm
    - Chi·ªÅu d√†i c√°nh: 1.0 - 6.9 cm
    - Chi·ªÅu r·ªông c√°nh: 0.1 - 2.5 cm
    """)

# Th√¥ng tin v·ªÅ models
with st.expander("V·ªÅ c√°c Models"):
    st.markdown("""
    **3 Models ƒë∆∞·ª£c s·ª≠ d·ª•ng:**
    
    **1. Random Forest (Bagging)**
    - 20 decision trees ƒë∆∞·ª£c train ƒë·ªôc l·∫≠p
    - Bootstrap sampling v·ªõi ho√†n l·∫°i
    - Majority voting ƒë·ªÉ d·ª± ƒëo√°n
    - Gi·∫£m variance, tr√°nh overfitting
    
    **2. Voting Classifier**
    - K·∫øt h·ª£p 3 models: Decision Tree, Logistic Regression, KNN
    - Hard voting (majority vote)
    - T·∫≠n d·ª•ng diverse models
    
    **3. XGBoost Custom (Gradient Boosting)**
    - 50 sequential trees
    - Fit residuals c·ªßa model tr∆∞·ªõc
    - Learning rate = 0.1
    - Gi·∫£m bias, c·∫£i thi·ªán accuracy
    
    **4. AdaBoost (Boosting)**
    - 50 weak learners (decision stumps)
    - One-vs-Rest strategy cho multiclass
    - Adaptive weighting
    - Sequential training v·ªõi error-based reweighting
                
    """)

# Footer
st.markdown("---")
st.markdown(
    """
    <div style='text-align: center'>
        <p>üéì ƒê·ªì √°n cu·ªëi k·ª≥ m√¥n Machine Learning</p>
        <p>üìö ƒê·ªÅ t√†i: Ph√¢n lo·∫°i Hoa Iris v·ªõi Ensemble Models</p>
    </div>
    """,
    unsafe_allow_html=True
)